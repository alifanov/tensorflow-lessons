{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/batches.meta\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n",
      "Size of:\n",
      "- Training-set:\t\t50000\n",
      "- Test-set:\t\t10000\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "# Functions and classes for loading and using the Inception model.\n",
    "import inception\n",
    "\n",
    "# We use Pretty Tensor to define the new classifier.\n",
    "import prettytensor as pt\n",
    "\n",
    "import cifar10\n",
    "from cifar10 import num_classes\n",
    "cifar10.maybe_download_and_extract()\n",
    "\n",
    "class_names = cifar10.load_class_names()\n",
    "images_train, cls_train, labels_train = cifar10.load_training_data()\n",
    "images_test, cls_test, labels_test = cifar10.load_test_data()\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(images_train)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(images_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Inception v3 Model ...\n",
      "Data has apparently already been downloaded and unpacked.\n",
      "- Processing image:  50000 / 50000\n",
      "- Data saved to cache-file: data/CIFAR-10/inception_cifar10_train.pkl\n",
      "- Processing image:  10000 / 10000\n",
      "- Data saved to cache-file: data/CIFAR-10/inception_cifar10_test.pkl\n"
     ]
    }
   ],
   "source": [
    "inception.maybe_download()\n",
    "model = inception.Inception()\n",
    "\n",
    "from inception import transfer_values_cache\n",
    "file_path_cache_train = os.path.join(cifar10.data_path, 'inception_cifar10_train.pkl')\n",
    "file_path_cache_test = os.path.join(cifar10.data_path, 'inception_cifar10_test.pkl')\n",
    "images_scaled = images_train * 255.0\n",
    "\n",
    "transfer_values_train = transfer_values_cache(cache_path=file_path_cache_train,\n",
    "                                              images=images_scaled,\n",
    "                                              model=model)\n",
    "\n",
    "images_scaled = images_test * 255.0\n",
    "\n",
    "transfer_values_test = transfer_values_cache(cache_path=file_path_cache_test,\n",
    "                                             images=images_scaled,\n",
    "                                             model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "transfer_len = model.transfer_len\n",
    "x = tf.placeholder(tf.float32, shape=[None, transfer_len], name='x')\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "x_pretty = pt.wrap(x)\n",
    "\n",
    "with pt.defaults_scope(activation_fn=tf.nn.relu):\n",
    "    y_pred, loss = x_pretty.\\\n",
    "        fully_connected(size=1024, name='layer_fc1').\\\n",
    "        softmax_classifier(num_classes=num_classes, labels=y_true)\n",
    "        \n",
    "global_step = tf.Variable(initial_value=0,\n",
    "                          name='global_step', trainable=False)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss, global_step)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "def random_batch():\n",
    "    # Number of images (transfer-values) in the training-set.\n",
    "    num_images = len(transfer_values_train)\n",
    "\n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=train_batch_size,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random x and y-values.\n",
    "    # We use the transfer-values instead of images as x-values.\n",
    "    x_batch = transfer_values_train[idx]\n",
    "    y_batch = labels_train[idx]\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def optimize(num_iterations):\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images (transfer-values) and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch = random_batch()\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        # We also want to retrieve the global_step counter.\n",
    "        i_global, _ = session.run([global_step, optimizer],\n",
    "                                  feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status to screen every 100 iterations (and last).\n",
    "        if (i_global % 100 == 0) or (i == num_iterations - 1):\n",
    "            # Calculate the accuracy on the training-batch.\n",
    "            batch_acc = session.run(accuracy,\n",
    "                                    feed_dict=feed_dict_train)\n",
    "\n",
    "            # Print status.\n",
    "            msg = \"Global Step: {0:>6}, Training Batch Accuracy: {1:>6.1%}\"\n",
    "            print(msg.format(i_global, batch_acc))\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "def predict_cls(transfer_values, labels, cls_true):\n",
    "    # Number of images.\n",
    "    num_images = len(transfer_values)\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_images, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_images:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + batch_size, num_images)\n",
    "\n",
    "        # Create a feed-dict with the images and labels\n",
    "        # between index i and j.\n",
    "        feed_dict = {x: transfer_values[i:j],\n",
    "                     y_true: labels[i:j]}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "        \n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    return correct, cls_pred\n",
    "\n",
    "def predict_cls_test():\n",
    "    return predict_cls(transfer_values = transfer_values_test,\n",
    "                       labels = labels_test,\n",
    "                       cls_true = cls_test)\n",
    "\n",
    "def classification_accuracy(correct):\n",
    "    # When averaging a boolean array, False means 0 and True means 1.\n",
    "    # So we are calculating: number of True / len(correct) which is\n",
    "    # the same as the classification accuracy.\n",
    "\n",
    "    # Return the classification accuracy\n",
    "    # and the number of correct classifications.\n",
    "    return correct.mean(), correct.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:    100, Training Batch Accuracy:  82.8%\n",
      "Global Step:    200, Training Batch Accuracy:  89.1%\n",
      "Global Step:    300, Training Batch Accuracy:  92.2%\n",
      "Global Step:    400, Training Batch Accuracy:  84.4%\n",
      "Global Step:    500, Training Batch Accuracy:  90.6%\n",
      "Global Step:    600, Training Batch Accuracy:  90.6%\n",
      "Global Step:    700, Training Batch Accuracy:  95.3%\n",
      "Global Step:    800, Training Batch Accuracy:  90.6%\n",
      "Global Step:    900, Training Batch Accuracy:  90.6%\n",
      "Global Step:   1000, Training Batch Accuracy:  90.6%\n",
      "Global Step:   1100, Training Batch Accuracy:  92.2%\n",
      "Global Step:   1200, Training Batch Accuracy:  87.5%\n",
      "Global Step:   1300, Training Batch Accuracy:  85.9%\n",
      "Global Step:   1400, Training Batch Accuracy:  89.1%\n",
      "Global Step:   1500, Training Batch Accuracy:  93.8%\n",
      "Global Step:   1600, Training Batch Accuracy:  95.3%\n",
      "Global Step:   1700, Training Batch Accuracy:  87.5%\n",
      "Global Step:   1800, Training Batch Accuracy:  96.9%\n",
      "Global Step:   1900, Training Batch Accuracy:  89.1%\n",
      "Global Step:   2000, Training Batch Accuracy:  92.2%\n",
      "Global Step:   2100, Training Batch Accuracy:  95.3%\n",
      "Global Step:   2200, Training Batch Accuracy:  93.8%\n",
      "Global Step:   2300, Training Batch Accuracy:  98.4%\n",
      "Global Step:   2400, Training Batch Accuracy:  89.1%\n",
      "Global Step:   2500, Training Batch Accuracy:  92.2%\n",
      "Global Step:   2600, Training Batch Accuracy:  95.3%\n",
      "Global Step:   2700, Training Batch Accuracy:  85.9%\n",
      "Global Step:   2800, Training Batch Accuracy:  90.6%\n",
      "Global Step:   2900, Training Batch Accuracy:  93.8%\n",
      "Global Step:   3000, Training Batch Accuracy:  92.2%\n",
      "Global Step:   3100, Training Batch Accuracy:  98.4%\n",
      "Global Step:   3200, Training Batch Accuracy:  92.2%\n",
      "Global Step:   3300, Training Batch Accuracy:  92.2%\n",
      "Global Step:   3400, Training Batch Accuracy:  96.9%\n",
      "Global Step:   3500, Training Batch Accuracy:  90.6%\n",
      "Global Step:   3600, Training Batch Accuracy:  95.3%\n",
      "Global Step:   3700, Training Batch Accuracy:  95.3%\n",
      "Global Step:   3800, Training Batch Accuracy:  95.3%\n",
      "Global Step:   3900, Training Batch Accuracy:  93.8%\n",
      "Global Step:   4000, Training Batch Accuracy:  87.5%\n",
      "Global Step:   4100, Training Batch Accuracy:  98.4%\n",
      "Global Step:   4200, Training Batch Accuracy:  93.8%\n",
      "Global Step:   4300, Training Batch Accuracy:  96.9%\n",
      "Global Step:   4400, Training Batch Accuracy:  93.8%\n",
      "Global Step:   4500, Training Batch Accuracy:  96.9%\n",
      "Global Step:   4600, Training Batch Accuracy:  93.8%\n",
      "Global Step:   4700, Training Batch Accuracy:  90.6%\n",
      "Global Step:   4800, Training Batch Accuracy:  92.2%\n",
      "Global Step:   4900, Training Batch Accuracy:  95.3%\n",
      "Global Step:   5000, Training Batch Accuracy:  92.2%\n",
      "Time usage: 0:02:28\n",
      "Test accuracy: 89.3300%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    optimize(num_iterations=5000)\n",
    "    correct, cls_pred = predict_cls_test()\n",
    "    \n",
    "    # Classification accuracy and the number of correct classifications.\n",
    "    acc, num_correct = classification_accuracy(correct)\n",
    "    print('Test accuracy: {0:.4%}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
